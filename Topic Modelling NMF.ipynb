{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ebfcd06",
   "metadata": {},
   "source": [
    "### Topic Modelling NMF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bb5215b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sai Thejaswin\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_lda.py:28: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  EPS = np.finfo(np.float).eps\n"
     ]
    }
   ],
   "source": [
    "import twint\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 100\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "import string\n",
    "re.compile('<title>(.*)</title>')\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "from itertools import chain\n",
    "import collections\n",
    "from collections import Counter\n",
    "import gensim\n",
    "from gensim import corpora, models, similarities\n",
    "import pyLDAvis.gensim_models\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  \n",
    "\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.models.nmf import Nmf\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from operator import itemgetter # Already part of base Python\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "79cfc849",
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns_1 = pd.read_csv(r'C:\\Users\\Sai Thejaswin\\OneDrive\\Documents\\MS\\GSU\\Sprint_Project\\Data\\nouns_phrases_1.csv')\n",
    "nouns_1['nouns']=nouns_1['nouns'].astype('str')\n",
    "nouns_1['nouns_embed'] = nouns_1['nouns'].apply(lambda x : x.replace(' ', '_'))\n",
    "nouns_1['tokenized'] = nouns_1.apply(lambda row: nltk.word_tokenize(row['nouns_embed']), axis=1)\n",
    "nouns_1_list = nouns_1['tokenized'].tolist()\n",
    "dictionary_1 = Dictionary(nouns_1_list)\n",
    "dictionary_1.filter_extremes(no_below=5, no_above=0.7)\n",
    "corpus_1 = [dictionary_1.doc2bow(document) for document in nouns_1_list]\n",
    "tfidf_gensim_1 = TfidfModel(corpus_1)\n",
    "vectors_gensim_1 = tfidf_gensim_1[corpus_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e522897b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run NMF model; try 10 topics for now\n",
    "model_nmf = Nmf(vectors_gensim_1, num_topics = 5, id2word = dictionary_1, kappa = 0.1,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "85d39c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word clouds per topic\n",
    "for t in range(model_nmf.num_topics):\n",
    "    wordcloud = WordCloud(\n",
    "        width = 750, \n",
    "        height = 500,\n",
    "        max_words = 200, \n",
    "        background_color = 'white').fit_words(dict(model_nmf.show_topic(t, 200)))\n",
    "    wordcloud.recolor(color_func = lambda *args, **kwargs: 'black')\n",
    "    plt.figure(figsize=[10,10])\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Topic #\" + str(t))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "74651126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>word_1</th>\n",
       "      <td>information</td>\n",
       "      <td>covid-</td>\n",
       "      <td>learn</td>\n",
       "      <td>covid</td>\n",
       "      <td>ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_2</th>\n",
       "      <td>mental_health</td>\n",
       "      <td>covid</td>\n",
       "      <td>nhs</td>\n",
       "      <td>boozallen</td>\n",
       "      <td>icu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_3</th>\n",
       "      <td></td>\n",
       "      <td>icu</td>\n",
       "      <td>va</td>\n",
       "      <td>mental_health</td>\n",
       "      <td>digitalhealth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_4</th>\n",
       "      <td>please</td>\n",
       "      <td>covid</td>\n",
       "      <td>electronic</td>\n",
       "      <td>download</td>\n",
       "      <td>hie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_5</th>\n",
       "      <td>uk</td>\n",
       "      <td>unprecedented_disruptions</td>\n",
       "      <td>data</td>\n",
       "      <td>cybersecurity</td>\n",
       "      <td>covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_6</th>\n",
       "      <td>digital_health</td>\n",
       "      <td>apple</td>\n",
       "      <td>digital</td>\n",
       "      <td>uk</td>\n",
       "      <td>app_workout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_7</th>\n",
       "      <td>public_health</td>\n",
       "      <td>find</td>\n",
       "      <td>youtube</td>\n",
       "      <td>learn_boozallen_epimaps</td>\n",
       "      <td>please</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_8</th>\n",
       "      <td>coronavirus</td>\n",
       "      <td>solving</td>\n",
       "      <td>electronic_case</td>\n",
       "      <td>talent_health_analytics_cyber</td>\n",
       "      <td>telehealth_remain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_9</th>\n",
       "      <td>'ll</td>\n",
       "      <td>join</td>\n",
       "      <td>digitalhealth</td>\n",
       "      <td>april</td>\n",
       "      <td>china</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_10</th>\n",
       "      <td>covid</td>\n",
       "      <td>health_app</td>\n",
       "      <td>may</td>\n",
       "      <td>new_cases</td>\n",
       "      <td>toughest_problems</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  topic_1                      topic_2            topic_3  \\\n",
       "word_1       information                       covid-              learn    \n",
       "word_2     mental_health                        covid                nhs    \n",
       "word_3                                            icu                 va    \n",
       "word_4            please                        covid         electronic    \n",
       "word_5                uk    unprecedented_disruptions               data    \n",
       "word_6    digital_health                        apple            digital    \n",
       "word_7     public_health                         find            youtube    \n",
       "word_8       coronavirus                      solving    electronic_case    \n",
       "word_9               'll                         join      digitalhealth    \n",
       "word_10             covid                   health_app                may   \n",
       "\n",
       "                                 topic_4              topic_5  \n",
       "word_1                            covid                   ai   \n",
       "word_2                        boozallen                  icu   \n",
       "word_3                    mental_health        digitalhealth   \n",
       "word_4                         download                  hie   \n",
       "word_5                    cybersecurity                covid   \n",
       "word_6                               uk          app_workout   \n",
       "word_7          learn_boozallen_epimaps               please   \n",
       "word_8    talent_health_analytics_cyber    telehealth_remain   \n",
       "word_9                            april                china   \n",
       "word_10                        new_cases    toughest_problems  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reorganize as dataframe for easier viewing\n",
    "topics_nmf = pd.DataFrame(model_nmf.show_topics())\n",
    "topics_nmf = topics_nmf[1].str.split('+', n = 10, expand = True)\n",
    "topics_nmf = topics_nmf.replace(r'\\d', '', regex=True)\n",
    "topics_nmf = topics_nmf.replace(r'\\*', '', regex=True)\n",
    "topics_nmf = topics_nmf.replace(r'\\\"', '', regex=True)\n",
    "topics_nmf = topics_nmf.replace(r'\\.', '', regex=True)\n",
    "topics_nmf.columns = ['word_1', 'word_2', 'word_3', 'word_4', 'word_5'\n",
    "                      ,'word_6', 'word_7', 'word_8', 'word_9', 'word_10']\n",
    "topics_nmf = topics_nmf.transpose()\n",
    "topics_nmf.columns = ['topic_1', 'topic_2', 'topic_3', 'topic_4', 'topic_5']\n",
    "                      #'topic_6', 'topic_7', 'topic_8', 'topic_9', 'topic_10']\n",
    "\n",
    "topics_nmf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fdfdbd",
   "metadata": {},
   "source": [
    "# Phase-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c4ddeb1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>word_1</th>\n",
       "      <td>covid</td>\n",
       "      <td>information</td>\n",
       "      <td>public_health</td>\n",
       "      <td>covid-</td>\n",
       "      <td>covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_2</th>\n",
       "      <td></td>\n",
       "      <td>ai</td>\n",
       "      <td>learn</td>\n",
       "      <td>icu</td>\n",
       "      <td>icu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_3</th>\n",
       "      <td>information</td>\n",
       "      <td>learn</td>\n",
       "      <td>medical_things</td>\n",
       "      <td>neuralink</td>\n",
       "      <td>remote_patient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_4</th>\n",
       "      <td>rtされた数:</td>\n",
       "      <td>r_eicu_ツイート数:</td>\n",
       "      <td>surveillance_covid-_data_analytics_ai</td>\n",
       "      <td>august</td>\n",
       "      <td>covid-_electronic_case_reporting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_5</th>\n",
       "      <td>internet</td>\n",
       "      <td>covid</td>\n",
       "      <td>join</td>\n",
       "      <td>mental</td>\n",
       "      <td>healthtech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_6</th>\n",
       "      <td>read</td>\n",
       "      <td>trump</td>\n",
       "      <td>mental_health</td>\n",
       "      <td>september</td>\n",
       "      <td>onc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_7</th>\n",
       "      <td>iomt</td>\n",
       "      <td>singapore</td>\n",
       "      <td>health_technology</td>\n",
       "      <td>digitalhealth</td>\n",
       "      <td>internet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_8</th>\n",
       "      <td>us</td>\n",
       "      <td>belgium_icu</td>\n",
       "      <td>providertech_healthtech_healthcare_pophealth_...</td>\n",
       "      <td>r_eicu_ツイート数:</td>\n",
       "      <td>health_system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_9</th>\n",
       "      <td>electronic</td>\n",
       "      <td>electronic_tags_monitor_travellers</td>\n",
       "      <td>improving</td>\n",
       "      <td>health_information_exchange</td>\n",
       "      <td>please</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_10</th>\n",
       "      <td>remote_patient</td>\n",
       "      <td>canada</td>\n",
       "      <td>mh</td>\n",
       "      <td>femtech</td>\n",
       "      <td>coronavirus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 topic_1                               topic_2  \\\n",
       "word_1            covid                           information    \n",
       "word_2                                                     ai    \n",
       "word_3      information                                 learn    \n",
       "word_4          rtされた数:                         r_eicu_ツイート数:    \n",
       "word_5         internet                                 covid    \n",
       "word_6             read                                 trump    \n",
       "word_7             iomt                             singapore    \n",
       "word_8               us                           belgium_icu    \n",
       "word_9       electronic    electronic_tags_monitor_travellers    \n",
       "word_10   remote_patient                                canada   \n",
       "\n",
       "                                                   topic_3  \\\n",
       "word_1                                      public_health    \n",
       "word_2                                              learn    \n",
       "word_3                                     medical_things    \n",
       "word_4              surveillance_covid-_data_analytics_ai    \n",
       "word_5                                               join    \n",
       "word_6                                      mental_health    \n",
       "word_7                                  health_technology    \n",
       "word_8    providertech_healthtech_healthcare_pophealth_...   \n",
       "word_9                                          improving    \n",
       "word_10                                                 mh   \n",
       "\n",
       "                               topic_4                             topic_5  \n",
       "word_1                         covid-                               covid   \n",
       "word_2                            icu                                 icu   \n",
       "word_3                      neuralink                      remote_patient   \n",
       "word_4                         august    covid-_electronic_case_reporting   \n",
       "word_5                         mental                          healthtech   \n",
       "word_6                      september                                 onc   \n",
       "word_7                  digitalhealth                            internet   \n",
       "word_8                  r_eicu_ツイート数:                       health_system   \n",
       "word_9    health_information_exchange                              please   \n",
       "word_10                        femtech                         coronavirus  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns_2 = pd.read_csv(r'C:\\Users\\Sai Thejaswin\\OneDrive\\Documents\\MS\\GSU\\Sprint_Project\\Data\\nouns_phrases_2.csv')\n",
    "nouns_2['nouns']=nouns_2['nouns'].astype('str')\n",
    "nouns_2['nouns_embed'] = nouns_2['nouns'].apply(lambda x : x.replace(' ', '_'))\n",
    "nouns_2['tokenized'] = nouns_2.apply(lambda row: nltk.word_tokenize(row['nouns_embed']), axis=1)\n",
    "nouns_2_list = nouns_2['tokenized'].tolist()\n",
    "dictionary_2 = Dictionary(nouns_2_list)\n",
    "dictionary_2.filter_extremes(no_below=5, no_above=0.7)\n",
    "corpus_2 = [dictionary_2.doc2bow(document) for document in nouns_2_list]\n",
    "tfidf_gensim_2 = TfidfModel(corpus_2)\n",
    "vectors_gensim_2 = tfidf_gensim_2[corpus_2]\n",
    "# Run NMF model; try 10 topics for now\n",
    "model_nmf_2 = Nmf(vectors_gensim_2, num_topics = 5, id2word = dictionary_2, kappa = 0.1, eval_every = 10, random_state = 42)\n",
    "\n",
    "\n",
    "# Reorganize as dataframe for easier viewing\n",
    "topics_nmf_2 = pd.DataFrame(model_nmf_2.show_topics())\n",
    "topics_nmf_2 = topics_nmf_2[1].str.split('+', n = 10, expand = True)\n",
    "topics_nmf_2 = topics_nmf_2.replace(r'\\d', '', regex=True)\n",
    "topics_nmf_2 = topics_nmf_2.replace(r'\\*', '', regex=True)\n",
    "topics_nmf_2 = topics_nmf_2.replace(r'\\\"', '', regex=True)\n",
    "topics_nmf_2 = topics_nmf_2.replace(r'\\.', '', regex=True)\n",
    "topics_nmf_2.columns = ['word_1', 'word_2', 'word_3', 'word_4', 'word_5',\n",
    "                      'word_6', 'word_7', 'word_8', 'word_9', 'word_10']\n",
    "topics_nmf_2 = topics_nmf_2.transpose()\n",
    "topics_nmf_2.columns = ['topic_1', 'topic_2', 'topic_3', 'topic_4', 'topic_5']\n",
    "                      #'topic_6', 'topic_7', 'topic_8', 'topic_9', 'topic_10']\n",
    "\n",
    "topics_nmf_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3202682f",
   "metadata": {},
   "source": [
    "# Phase-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "86df9635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>word_1</th>\n",
       "      <td>learn</td>\n",
       "      <td>ai</td>\n",
       "      <td>information</td>\n",
       "      <td>april</td>\n",
       "      <td>covid-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_2</th>\n",
       "      <td>covid</td>\n",
       "      <td>hie</td>\n",
       "      <td>may</td>\n",
       "      <td>ai</td>\n",
       "      <td>icu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_3</th>\n",
       "      <td>read</td>\n",
       "      <td>covid-</td>\n",
       "      <td>feasibility_analysis_syndromic_surveillance</td>\n",
       "      <td>please</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_4</th>\n",
       "      <td>covid</td>\n",
       "      <td>artificial_intelligence</td>\n",
       "      <td>health_information_exchange</td>\n",
       "      <td>algorithm</td>\n",
       "      <td>uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_5</th>\n",
       "      <td>join</td>\n",
       "      <td>find</td>\n",
       "      <td>public_health</td>\n",
       "      <td>visit</td>\n",
       "      <td>digitaldivide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_6</th>\n",
       "      <td>digital</td>\n",
       "      <td>algorithms</td>\n",
       "      <td>algorithm</td>\n",
       "      <td>electronic_health_records</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_7</th>\n",
       "      <td>please</td>\n",
       "      <td>biden</td>\n",
       "      <td>role</td>\n",
       "      <td>twitch</td>\n",
       "      <td>safety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_8</th>\n",
       "      <td>twitter</td>\n",
       "      <td>role</td>\n",
       "      <td>dna</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>drvanessawalker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_9</th>\n",
       "      <td>india</td>\n",
       "      <td>epidemiological_surveillance</td>\n",
       "      <td>covid</td>\n",
       "      <td>twitchsupport</td>\n",
       "      <td>teamsutter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_10</th>\n",
       "      <td>icu</td>\n",
       "      <td>health_care</td>\n",
       "      <td>youtube</td>\n",
       "      <td>california</td>\n",
       "      <td>treat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           topic_1                         topic_2  \\\n",
       "word_1      learn                              ai    \n",
       "word_2      covid                             hie    \n",
       "word_3       read                          covid-    \n",
       "word_4      covid         artificial_intelligence    \n",
       "word_5       join                            find    \n",
       "word_6    digital                      algorithms    \n",
       "word_7     please                           biden    \n",
       "word_8    twitter                            role    \n",
       "word_9      india    epidemiological_surveillance    \n",
       "word_10        icu                     health_care   \n",
       "\n",
       "                                               topic_3  \\\n",
       "word_1                                    information    \n",
       "word_2                                            may    \n",
       "word_3    feasibility_analysis_syndromic_surveillance    \n",
       "word_4                    health_information_exchange    \n",
       "word_5                                  public_health    \n",
       "word_6                                      algorithm    \n",
       "word_7                                           role    \n",
       "word_8                                            dna    \n",
       "word_9                                          covid    \n",
       "word_10                                        youtube   \n",
       "\n",
       "                             topic_4            topic_5  \n",
       "word_1                        april             covid-   \n",
       "word_2                           ai                icu   \n",
       "word_3                       please                      \n",
       "word_4                    algorithm                 uk   \n",
       "word_5                        visit      digitaldivide   \n",
       "word_6    electronic_health_records                      \n",
       "word_7                       twitch             safety   \n",
       "word_8                   healthcare    drvanessawalker   \n",
       "word_9                twitchsupport         teamsutter   \n",
       "word_10                   california              treat  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns_3 = pd.read_csv(r'C:\\Users\\Sai Thejaswin\\OneDrive\\Documents\\MS\\GSU\\Sprint_Project\\Data\\nouns_phrases_3.csv')\n",
    "nouns_3['nouns']=nouns_3['nouns'].astype('str')\n",
    "nouns_3['nouns_embed'] = nouns_3['nouns'].apply(lambda x : x.replace(' ', '_'))\n",
    "nouns_3['tokenized'] = nouns_3.apply(lambda row: nltk.word_tokenize(row['nouns_embed']), axis=1)\n",
    "nouns_3_list = nouns_3['tokenized'].tolist()\n",
    "dictionary_3 = Dictionary(nouns_3_list)\n",
    "dictionary_3.filter_extremes(no_below=5, no_above=0.7)\n",
    "corpus_3 = [dictionary_3.doc2bow(document) for document in nouns_3_list]\n",
    "tfidf_gensim_3 = TfidfModel(corpus_3)\n",
    "vectors_gensim_3 = tfidf_gensim_3[corpus_3]\n",
    "# Run NMF model; try 10 topics for now\n",
    "model_nmf_3 = Nmf(vectors_gensim_3, num_topics = 5, id2word = dictionary_3, kappa = 0.1, eval_every = 10, random_state = 42)\n",
    "\n",
    "\n",
    "# Reorganize as dataframe for easier viewing\n",
    "topics_nmf_3 = pd.DataFrame(model_nmf_3.show_topics())\n",
    "topics_nmf_3 = topics_nmf_3[1].str.split('+', n = 10, expand = True)\n",
    "topics_nmf_3 = topics_nmf_3.replace(r'\\d', '', regex=True)\n",
    "topics_nmf_3 = topics_nmf_3.replace(r'\\*', '', regex=True)\n",
    "topics_nmf_3 = topics_nmf_3.replace(r'\\\"', '', regex=True)\n",
    "topics_nmf_3 = topics_nmf_3.replace(r'\\.', '', regex=True)\n",
    "topics_nmf_3.columns = ['word_1', 'word_2', 'word_3', 'word_4', 'word_5',\n",
    "                      'word_6', 'word_7', 'word_8', 'word_9', 'word_10']\n",
    "topics_nmf_3 = topics_nmf_3.transpose()\n",
    "topics_nmf_3.columns = ['topic_1', 'topic_2', 'topic_3', 'topic_4', 'topic_5']\n",
    "                     # 'topic_6', 'topic_7', 'topic_8', 'topic_9', 'topic_10']\n",
    "\n",
    "topics_nmf_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f845a564",
   "metadata": {},
   "source": [
    "# Phase-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "30ef950c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>word_1</th>\n",
       "      <td>covid-</td>\n",
       "      <td>ai</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>information</td>\n",
       "      <td>ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_2</th>\n",
       "      <td>read</td>\n",
       "      <td>date</td>\n",
       "      <td>epic_anthem_strike_deal_support</td>\n",
       "      <td>covid</td>\n",
       "      <td>may</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_3</th>\n",
       "      <td>usd</td>\n",
       "      <td>read</td>\n",
       "      <td>electronic</td>\n",
       "      <td></td>\n",
       "      <td>ontario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_4</th>\n",
       "      <td>victoria</td>\n",
       "      <td>digital</td>\n",
       "      <td>health_technology</td>\n",
       "      <td>unknown_wallet</td>\n",
       "      <td>l_biozhena_files_downloads</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_5</th>\n",
       "      <td>btc</td>\n",
       "      <td>june</td>\n",
       "      <td>vc</td>\n",
       "      <td>vic</td>\n",
       "      <td>obgyn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_6</th>\n",
       "      <td>nsw</td>\n",
       "      <td>ehr</td>\n",
       "      <td>eu</td>\n",
       "      <td>ps</td>\n",
       "      <td>learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_7</th>\n",
       "      <td>digitalhealth</td>\n",
       "      <td>unknown_wallet</td>\n",
       "      <td>international_health_week_review</td>\n",
       "      <td>digital_digitalhealth_health</td>\n",
       "      <td>precisionmedicine_womenshealth_fertilityaware...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_8</th>\n",
       "      <td>blockchain</td>\n",
       "      <td>data</td>\n",
       "      <td>scripps</td>\n",
       "      <td>please</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_9</th>\n",
       "      <td>qr</td>\n",
       "      <td>btc</td>\n",
       "      <td>contact</td>\n",
       "      <td>digital_health</td>\n",
       "      <td>nps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_10</th>\n",
       "      <td>nhs</td>\n",
       "      <td>rt</td>\n",
       "      <td>obgyn</td>\n",
       "      <td>electronic</td>\n",
       "      <td>vicgovdh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 topic_1           topic_2  \\\n",
       "word_1           covid-                ai    \n",
       "word_2             read              date    \n",
       "word_3              usd              read    \n",
       "word_4         victoria           digital    \n",
       "word_5              btc              june    \n",
       "word_6              nsw               ehr    \n",
       "word_7    digitalhealth    unknown_wallet    \n",
       "word_8       blockchain              data    \n",
       "word_9               qr               btc    \n",
       "word_10              nhs                rt   \n",
       "\n",
       "                                    topic_3                         topic_4  \\\n",
       "word_1                          healthcare                     information    \n",
       "word_2     epic_anthem_strike_deal_support                           covid    \n",
       "word_3                          electronic                                    \n",
       "word_4                   health_technology                  unknown_wallet    \n",
       "word_5                                  vc                             vic    \n",
       "word_6                                  eu                              ps    \n",
       "word_7    international_health_week_review    digital_digitalhealth_health    \n",
       "word_8                             scripps                          please    \n",
       "word_9                             contact                  digital_health    \n",
       "word_10                               obgyn                      electronic   \n",
       "\n",
       "                                                   topic_5  \n",
       "word_1                                                 ai   \n",
       "word_2                                                may   \n",
       "word_3                                            ontario   \n",
       "word_4                         l_biozhena_files_downloads   \n",
       "word_5                                              obgyn   \n",
       "word_6                                              learn   \n",
       "word_7    precisionmedicine_womenshealth_fertilityaware...  \n",
       "word_8                                                      \n",
       "word_9                                                nps   \n",
       "word_10                                           vicgovdh  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns_4 = pd.read_csv(r'C:\\Users\\Sai Thejaswin\\OneDrive\\Documents\\MS\\GSU\\Sprint_Project\\Data\\nouns_phrases_4.csv')\n",
    "nouns_4['nouns']=nouns_4['nouns'].astype('str')\n",
    "nouns_4['nouns_embed'] = nouns_4['nouns'].apply(lambda x : x.replace(' ', '_'))\n",
    "nouns_4['tokenized'] = nouns_4.apply(lambda row: nltk.word_tokenize(row['nouns_embed']), axis=1)\n",
    "nouns_4_list = nouns_4['tokenized'].tolist()\n",
    "dictionary_4 = Dictionary(nouns_4_list)\n",
    "dictionary_4.filter_extremes(no_below=5, no_above=0.7)\n",
    "corpus_4 = [dictionary_4.doc2bow(document) for document in nouns_4_list]\n",
    "tfidf_gensim_4 = TfidfModel(corpus_4)\n",
    "vectors_gensim_4 = tfidf_gensim_4[corpus_4]\n",
    "# Run NMF model; try 10 topics for now\n",
    "model_nmf_4 = Nmf(vectors_gensim_4, num_topics = 5, id2word = dictionary_4, kappa = 0.1, eval_every = 10, random_state = 42)\n",
    "\n",
    "\n",
    "# Reorganize as dataframe for easier viewing\n",
    "topics_nmf_4 = pd.DataFrame(model_nmf_4.show_topics())\n",
    "topics_nmf_4 = topics_nmf_4[1].str.split('+', n = 10, expand = True)\n",
    "topics_nmf_4 = topics_nmf_4.replace(r'\\d', '', regex=True)\n",
    "topics_nmf_4 = topics_nmf_4.replace(r'\\*', '', regex=True)\n",
    "topics_nmf_4 = topics_nmf_4.replace(r'\\\"', '', regex=True)\n",
    "topics_nmf_4 = topics_nmf_4.replace(r'\\.', '', regex=True)\n",
    "topics_nmf_4.columns = ['word_1', 'word_2', 'word_3', 'word_4', 'word_5',\n",
    "                      'word_6', 'word_7', 'word_8', 'word_9', 'word_10']\n",
    "topics_nmf_4 = topics_nmf_4.transpose()\n",
    "topics_nmf_4.columns = ['topic_1', 'topic_2', 'topic_3', 'topic_4', 'topic_5']\n",
    "                      #'topic_6', 'topic_7', 'topic_8', 'topic_9', 'topic_10']\n",
    "\n",
    "topics_nmf_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2112e46",
   "metadata": {},
   "source": [
    "# Phase 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ba9bd464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>word_1</th>\n",
       "      <td>digitalhealth</td>\n",
       "      <td>ai</td>\n",
       "      <td></td>\n",
       "      <td>mental</td>\n",
       "      <td>internet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_2</th>\n",
       "      <td>rt</td>\n",
       "      <td>electronic</td>\n",
       "      <td>record</td>\n",
       "      <td>learn</td>\n",
       "      <td>read</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_3</th>\n",
       "      <td>mental_health</td>\n",
       "      <td>rtされた数:</td>\n",
       "      <td>us</td>\n",
       "      <td>iot</td>\n",
       "      <td>cybersecurity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_4</th>\n",
       "      <td>god</td>\n",
       "      <td></td>\n",
       "      <td>artificial_intelligence</td>\n",
       "      <td>artificial_intelligence</td>\n",
       "      <td>records_ehrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_5</th>\n",
       "      <td>california</td>\n",
       "      <td>immigrants_tuberculosis</td>\n",
       "      <td>前日比:_受け取ったリプライ数:_前日比:_いいねされた数:_前日比:</td>\n",
       "      <td></td>\n",
       "      <td>medical_technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_6</th>\n",
       "      <td>va</td>\n",
       "      <td>digital</td>\n",
       "      <td>read</td>\n",
       "      <td>music_history</td>\n",
       "      <td>rt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_7</th>\n",
       "      <td>前日比:_受け取ったリプライ数:_前日比:_いいねされた数:_前日比:</td>\n",
       "      <td>source_electronic</td>\n",
       "      <td>records</td>\n",
       "      <td>artificialintelligence</td>\n",
       "      <td>rtされた数:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_8</th>\n",
       "      <td>barcelona</td>\n",
       "      <td>前日比:_受け取ったリプライ数:_前日比:_いいねされた数:_前日比:</td>\n",
       "      <td>care</td>\n",
       "      <td>vr</td>\n",
       "      <td>learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_9</th>\n",
       "      <td>records</td>\n",
       "      <td>cybersecurity</td>\n",
       "      <td>gps</td>\n",
       "      <td>electronic_devices</td>\n",
       "      <td>immigrants_tuberculosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_10</th>\n",
       "      <td>ministry</td>\n",
       "      <td>barcelona</td>\n",
       "      <td>seattle</td>\n",
       "      <td>telemedicine</td>\n",
       "      <td>diagnostic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       topic_1  \\\n",
       "word_1                          digitalhealth    \n",
       "word_2                                     rt    \n",
       "word_3                          mental_health    \n",
       "word_4                                    god    \n",
       "word_5                             california    \n",
       "word_6                                     va    \n",
       "word_7    前日比:_受け取ったリプライ数:_前日比:_いいねされた数:_前日比:    \n",
       "word_8                              barcelona    \n",
       "word_9                                records    \n",
       "word_10                               ministry   \n",
       "\n",
       "                                       topic_2  \\\n",
       "word_1                                     ai    \n",
       "word_2                             electronic    \n",
       "word_3                                rtされた数:    \n",
       "word_4                                           \n",
       "word_5                immigrants_tuberculosis    \n",
       "word_6                                digital    \n",
       "word_7                      source_electronic    \n",
       "word_8    前日比:_受け取ったリプライ数:_前日比:_いいねされた数:_前日比:    \n",
       "word_9                          cybersecurity    \n",
       "word_10                              barcelona   \n",
       "\n",
       "                                       topic_3                    topic_4  \\\n",
       "word_1                                                            mental    \n",
       "word_2                                 record                      learn    \n",
       "word_3                                     us                        iot    \n",
       "word_4                artificial_intelligence    artificial_intelligence    \n",
       "word_5    前日比:_受け取ったリプライ数:_前日比:_いいねされた数:_前日比:                               \n",
       "word_6                                   read              music_history    \n",
       "word_7                                records     artificialintelligence    \n",
       "word_8                                   care                         vr    \n",
       "word_9                                    gps         electronic_devices    \n",
       "word_10                                seattle               telemedicine   \n",
       "\n",
       "                           topic_5  \n",
       "word_1                   internet   \n",
       "word_2                       read   \n",
       "word_3              cybersecurity   \n",
       "word_4               records_ehrs   \n",
       "word_5         medical_technology   \n",
       "word_6                         rt   \n",
       "word_7                    rtされた数:   \n",
       "word_8                      learn   \n",
       "word_9    immigrants_tuberculosis   \n",
       "word_10                 diagnostic  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns_5 = pd.read_csv(r'C:\\Users\\Sai Thejaswin\\OneDrive\\Documents\\MS\\GSU\\Sprint_Project\\Data\\nouns_phrases_5.csv')\n",
    "nouns_5['nouns']=nouns_5['nouns'].astype('str')\n",
    "nouns_5['nouns_embed'] = nouns_5['nouns'].apply(lambda x : x.replace(' ', '_'))\n",
    "nouns_5['tokenized'] = nouns_5.apply(lambda row: nltk.word_tokenize(row['nouns_embed']), axis=1)\n",
    "nouns_5_list = nouns_5['tokenized'].tolist()\n",
    "dictionary_5 = Dictionary(nouns_5_list)\n",
    "dictionary_5.filter_extremes(no_below=5, no_above=0.7)\n",
    "corpus_5 = [dictionary_5.doc2bow(document) for document in nouns_5_list]\n",
    "tfidf_gensim_5 = TfidfModel(corpus_5)\n",
    "vectors_gensim_5 = tfidf_gensim_5[corpus_5]\n",
    "# Run NMF model; try 10 topics for now\n",
    "model_nmf_5 = Nmf(vectors_gensim_5, num_topics = 5, id2word = dictionary_5, kappa = 0.1, eval_every = 10, random_state = 42)\n",
    "\n",
    "\n",
    "# Reorganize as dataframe for easier viewing\n",
    "topics_nmf_5 = pd.DataFrame(model_nmf_5.show_topics())\n",
    "topics_nmf_5 = topics_nmf_5[1].str.split('+', n = 10, expand = True)\n",
    "topics_nmf_5 = topics_nmf_5.replace(r'\\d', '', regex=True)\n",
    "topics_nmf_5 = topics_nmf_5.replace(r'\\*', '', regex=True)\n",
    "topics_nmf_5 = topics_nmf_5.replace(r'\\\"', '', regex=True)\n",
    "topics_nmf_5 = topics_nmf_5.replace(r'\\.', '', regex=True)\n",
    "topics_nmf_5.columns = ['word_1', 'word_2', 'word_3', 'word_4', 'word_5',\n",
    "                      'word_6', 'word_7', 'word_8', 'word_9', 'word_10']\n",
    "topics_nmf_5 = topics_nmf_5.transpose()\n",
    "topics_nmf_5.columns = ['topic_1', 'topic_2', 'topic_3', 'topic_4', 'topic_5']\n",
    "                      #'topic_6', 'topic_7', 'topic_8', 'topic_9', 'topic_10']\n",
    "\n",
    "topics_nmf_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd90591",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
